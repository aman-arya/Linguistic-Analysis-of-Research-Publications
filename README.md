# Linguistics_Final_Project    

## Python files in the project:    
    
1. **confusion_matrix.py** used to calculate the confusion matrix of the pos tags for all the classes.     
2. **get_vocab_data.py** used to generated the tokens and types of the titles and abstracts of each class.     
3. **histogram.py** used to plot the histograms of fractios of every pos tag in every class.    
4. **ngram_analysis.py** used for the analysis and plots of the ngram models of the pos tag sequence of the abstracts of every class.    
5. **pos_tgging.py** used for generating the pos tags of the abstracts and titles of every class.    
6. **segregate.py** to segregate the original dataset into six subject classes.    
7. **tag_analysis.py** to generate the counts of the universal tagsets for every abstract.    
8. **tg_ratios.py** used to calculate the ratio of number of one tag to number of another tag in the abstracts.    
9. **tag_sequences.py** for generating the ngram model of the pos tags of the abstracts and titles.    
10. **tools.py** auxillary functions that were used in the other codes.    
11. **universal_tagging.py** for generating the pos tags of the abstracts and mapping them to the universal tagset of nltk.   
